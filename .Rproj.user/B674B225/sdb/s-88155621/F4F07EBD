{
    "contents" : "---\ntitle: \"Predictive Model for Excercise\"\nauthor: \"Erich Donahue\"\ndate: \"02/22/2015\"\noutput: html_document\n---\n\nIntroduction\n------------------------\n\nUsing devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement â€“ a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. In this project, your goal will be to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways. More information is available from the website here:\n\nhttp://groupware.les.inf.puc-rio.br/har (see the section on the Weight Lifting Exercise Dataset). \n\n\n\nThe five barbell lifting methods are:\n\n- **A:** Correct execution\n- **B:** Throwing the elbows to the front\n- **C:** Lifting the dumbell only halfway\n- **D:** Lowering the dumbell only halfway\n- **E:** Throwing the hips to the front\n\nWe will attempt to build a model that classifies training and test data into one of the five outcomes.\n\n\n\nData Loading and Exploration\n------------------------\n\nFirst the data is downloaded from the source and read into data frames:\n\n```{r, message=FALSE}\nlibrary(caret)\nlibrary(ggplot2)\n\nif (!file.exists(\"train.csv\")) {\n  download.file(\"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv\", \n                destfile = \"train.csv\", method=\"curl\")\n}\nif (!file.exists(\"test.csv\")) {\n  download.file(\"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv\", \n                destfile = \"test.csv\", method=\"curl\")\n}\n\nraw_train <- read.csv(\"train.csv\", na.strings = c(\"NA\",\"\"))\nraw_test <- read.csv(\"test.csv\", na.strings = c(\"NA\",\"\"))\n```\n\n\nSecond, we will examine the structure and output distribution of the sets:\n\n```{r}\ndim(raw_train)\ndim(raw_test)\n```\n```{r, eval=FALSE} raw_train[1:4,] ```\n```{r}\ntable(raw_train$classe)\n```\n\n\n\n\nData Preparation\n------------------------\n\nSince we want to only learn from data without missing observations we should first test for missings.\n\n```{r}\ncomp <- sum(complete.cases(raw_train))\ncomp\n```\n\n\nAs there are only `r comp` complete observations out of a total `r nrow(raw_train)` records it seems likely that there are some columns which are sparsely populated.\n\nThe following code tests for and removes columns with any missing values:\n```{r}\nbadCols <- sapply(raw_train, function(x)any(is.na(x)))\ntable(badCols)\n\ngoodCols<- names(badCols[badCols==FALSE])\ntrain <- raw_train[, names(raw_train) %in% goodCols]\n```\n\n\nFinally, there are some columns which do not provide estimation value, intended for meta analysis of users and configuration.  These are removed to further refine the training data:\n\n```{r}\ntrain <- train[, !(names(train) %in% list(\"X\", \"user_name\", \"raw_timestamp_part_1\", \"raw_timestamp_part_2\", \"cvtd_timestamp\", \"new_window\"))]\n```\n\n\n\n\nModel Development\n------------------------\n\nBefore fitting a model, I've split the train dataset into subtraining and validation components:\n\n```{r}\nintrain <- createDataPartition(train$classe, p = 0.7, list = FALSE)\ntrainTr <- train[intrain,]\ntrainTe <- train[-intrain,]\n```\n\nA model is trained using radom forest on the sub-training set.  Random forests can take a set with no pre-defined parameters, and with enough trees and processing power fit a model with reduced risk of overfitting.  Random forests also have the helpful feature of providing information on the importance of variables within the model.  The method below fits the sub-training set on classe with a relatively robust, 500, number of trees.\n\n\n\n```{r, message=FALSE}\nlibrary(randomForest)\nset.seed(4252015)\nmodel <- randomForest(classe ~ ., data = trainTr, ntree = 500)\n```\n\nOur model demonstrates a relatively low level for the out of bag estimate, at 0.22%.  The initial confusion matrix shows a near-perfect fit on the sub-training set.\n\n```{r}\nmodel\nconfus <-  data.frame(model$confusion)\nacc <- sum(confus$class.error)\n```\n\nA high accuracy value is seen at `r 100 - acc`%.\n\n\n\nTo further test the model's predictive power we can test using the sub-validation set:\n```{r}\ntr_pred <- predict(model, trainTr) \nte_pred <- predict(model, trainTe)\ntable(tr_pred, trainTr$classe)\ntable(te_pred, trainTe$classe)\n```\n\nThe model demonstrates perfect prediciton on the sub-training set with a relatively accurate prediction on the validation set.\n\nUsing the importance feature we can visualize the impacts of the 54 predictors in the model.  While many variables show a similar level of importance there are a few standouts.  Further reserarch may help to identify the relationship these represent.\n\n```{r}\nimport <- varImp(model)\nimport$var <- row.names(import)\nqplot(var, Overall, data=import)\n```\n\n\nFinally, we re-run a random forest on the full training set, to allow for predictions on the supplied test sample.\n\n```{r}\nmodelFin <- randomForest(classe ~ ., data = trainTr, ntree = 500)\nfin_predict <- predict(modelFin, raw_test)\nfin_predict\n```\n\n\n\nConclusion\n------------------------\nWhile the model seems accurate by many measures further investigation may help to reveal the relationships at work.  Since the important measure shows some clear standouts it may be useful to see if a simpler model can be developed to save processing overhead.  Alternatively, increasing the number of trees used or using a different learning approach could help to refine the predictive capability.\n",
    "created" : 1424640064068.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "1236755005",
    "id" : "F4F07EBD",
    "lastKnownWriteTime" : 1424649578,
    "path" : "~/Coursera/pracMachineLearning_Assessment/pracMachineLearning_Assessment.Rmd",
    "project_path" : "pracMachineLearning_Assessment.Rmd",
    "properties" : {
        "tempName" : "Untitled4"
    },
    "source_on_save" : false,
    "type" : "r_markdown"
}